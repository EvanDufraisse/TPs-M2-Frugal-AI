{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a0d3a2717bb48248e79839d929ea675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c56da4714e94476180d13f24058936fc",
              "IPY_MODEL_bad7121b7bd04acd8ae61fc49f4cbd3a",
              "IPY_MODEL_89f07412b4d64d4bb645cbbd997daea9"
            ],
            "layout": "IPY_MODEL_553ce819bc7a40469186f008adeefec6"
          }
        },
        "c56da4714e94476180d13f24058936fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5131e5a62c4d4e7fa3d3cd19068aae6b",
            "placeholder": "​",
            "style": "IPY_MODEL_200e6c2b01864797abedc2d7f635aaed",
            "value": "config.json: 100%"
          }
        },
        "bad7121b7bd04acd8ae61fc49f4cbd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7676d043b7427c936929a3162db0a9",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38a64b3a93d444dbae6736a0a282828e",
            "value": 285
          }
        },
        "89f07412b4d64d4bb645cbbd997daea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51752f856fc2404287d5007badad3f7d",
            "placeholder": "​",
            "style": "IPY_MODEL_f3861f247b334c2f81769c20e8aad40f",
            "value": " 285/285 [00:00&lt;00:00, 2.99kB/s]"
          }
        },
        "553ce819bc7a40469186f008adeefec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5131e5a62c4d4e7fa3d3cd19068aae6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200e6c2b01864797abedc2d7f635aaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7676d043b7427c936929a3162db0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a64b3a93d444dbae6736a0a282828e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51752f856fc2404287d5007badad3f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3861f247b334c2f81769c20e8aad40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5120f8e4349943208f54df6a63f35f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5e5916d1e7644e7a3a71132a2beb56b",
              "IPY_MODEL_aeeb8971d539407ea40dcbe9f41e3311",
              "IPY_MODEL_535904ba4d284bc380afd12a8f13f45c"
            ],
            "layout": "IPY_MODEL_c6efa6218d7444b68ed20c13fdccf5b1"
          }
        },
        "e5e5916d1e7644e7a3a71132a2beb56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_add67ccc0e304393b06efa036722e4a3",
            "placeholder": "​",
            "style": "IPY_MODEL_b735d0c26d4841b9966d54b6f95bc85e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "aeeb8971d539407ea40dcbe9f41e3311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee51cb8dfc554c6883a2fc7a27d71923",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b46afa62731648e0a33cc0c3df399dae",
            "value": 17756393
          }
        },
        "535904ba4d284bc380afd12a8f13f45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f0f81596f04ccaac13f80ca37a37f3",
            "placeholder": "​",
            "style": "IPY_MODEL_e575129332614dd5abe65fb124d357dd",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 32.7MB/s]"
          }
        },
        "c6efa6218d7444b68ed20c13fdccf5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add67ccc0e304393b06efa036722e4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b735d0c26d4841b9966d54b6f95bc85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee51cb8dfc554c6883a2fc7a27d71923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b46afa62731648e0a33cc0c3df399dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1f0f81596f04ccaac13f80ca37a37f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e575129332614dd5abe65fb124d357dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb5a85460dac4b76a8643b8ce4b3d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97eee5a112be4cb4ae1b0464da5da1d6",
              "IPY_MODEL_473a4874c9204919889df7830439f270",
              "IPY_MODEL_a20a85b8f5104512a0b9c77f8f93f04b"
            ],
            "layout": "IPY_MODEL_943f8fa6fa4842e98b2ac8473d718f69"
          }
        },
        "97eee5a112be4cb4ae1b0464da5da1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8219c7841d81478fbb3f0590c68f8db5",
            "placeholder": "​",
            "style": "IPY_MODEL_73debcbd38d946a98a7c066ccb6c8d84",
            "value": "vocab.txt: 100%"
          }
        },
        "473a4874c9204919889df7830439f270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e6a76c7958f4b139154e043eaac1907",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ad78ec17114502a1299ca7cf63883a",
            "value": 231508
          }
        },
        "a20a85b8f5104512a0b9c77f8f93f04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1bd4b5a6d684fa69b5b8f235420d8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_849d06633a8e43379e2d3db0ddcb454a",
            "value": " 232k/232k [00:00&lt;00:00, 2.70MB/s]"
          }
        },
        "943f8fa6fa4842e98b2ac8473d718f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8219c7841d81478fbb3f0590c68f8db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73debcbd38d946a98a7c066ccb6c8d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e6a76c7958f4b139154e043eaac1907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ad78ec17114502a1299ca7cf63883a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1bd4b5a6d684fa69b5b8f235420d8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849d06633a8e43379e2d3db0ddcb454a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Session 2 - Model Frugality\n",
        "\n",
        "Welcome to this second practical session of the Frugal AI series. In this sessions we'll delve into the concept of model frugality, and how to build models that are both accurate and efficient while minimizing the resources required to train them.\n",
        "\n"
      ],
      "metadata": {
        "id": "kTyQ59gJGF0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*During this session you're invited to measure the energy consumption of your code snippets for different models. This is not mandatory as not working on google colab and requiring further configuration on some laptops*\n",
        "\n",
        "\n",
        "### Energy Consumption Measurements\n",
        "In the perspective of quantifying the notion of Frugality of our approaches, we'll try to use the library `pyRAPL`to measure the energy consumption of cpus during training times of our different sets of models.\n",
        "The library isn't compatible with every piece of hardware or OS, if you encounter a problem in using it, just skip this part :)\n",
        "\n",
        "Try the snippet below to check it out!"
      ],
      "metadata": {
        "id": "Vb4ItYJUH4bB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test of an Energy Consumption estimation snippet"
      ],
      "metadata": {
        "id": "0PfdCluoIlmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyRAPL\n",
        "import time\n",
        "def sum_range(total = 1000000):\n",
        "    sum(range(total))\n",
        "    return\n",
        "\n",
        "all_powers = []\n",
        "start = 5\n",
        "end = 9\n",
        "for total in range(start, end):\n",
        "    pyRAPL.setup()\n",
        "    meter = pyRAPL.Measurement(\"energy-snippet\")\n",
        "    meter.begin()\n",
        "    sum_range(10**total)\n",
        "    meter.end()\n",
        "    all_powers.append(meter.result.pkg[0])\n",
        "# Power consumption is measured in micro-J\n",
        "for i in range(len(all_powers)):\n",
        "    print(f\"Summing 10^{start+i} numbers consummed {all_powers[i]} μJ\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "W8kb_xDAHSdB",
        "outputId": "9bbdf674-cdae-49c7-c61a-d24cfd67c12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:imports error \n",
            " You need to install pymongo>=3.9.0 in order to use MongoOutput \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyRAPLCantRecordEnergyConsumption",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyRAPLCantRecordEnergyConsumption\u001b[0m         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3ec6a4b1ce47>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpyRAPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmeter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyRAPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeasurement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"energy-snippet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmeter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyRAPL/pyRAPL.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(devices, socket_ids)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mraise\u001b[0m \u001b[0mPyRAPLBadSocketIdException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mpyRAPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msocket_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyRAPL/sensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, socket_ids)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_available_devices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPyRAPLCantRecordEnergyConsumption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket_ids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msocket_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPyRAPLCantRecordEnergyConsumption\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Dataset Preparation\n",
        "In this [data folder](https://drive.google.com/drive/folders/1jX4omja8UBcX3MNupX2rLmUJkzR9RhM6?usp=drive_link), you'll find two datasets.\n",
        "\n",
        "#### Amazon Reviews (6-class classification)\n",
        "The first one is another extract of the amazon reviews dataset as a six-category classification task. For all classes you have 500 examples that have been pre-selected and split randomly into a classical 80%/10%/10% train/val/test scheme.\n",
        "Categories that have been kept are the following:\n",
        "[\n",
        "    \"Beauty\",\n",
        "    \"Movies\",\n",
        "    \"Appliances\",\n",
        "    \"Digital Music\",\n",
        "    \"Software\",\n",
        "    \"Video_Games\"\n",
        "]\n",
        "\n",
        "#### WikiText-103-100k\n",
        "\n",
        "This second dataset is an extract from a known dataset of quality articles from wikipedia called WikiText-103, that comprises high quality articles from wikipedia. Later in the session this extract will allow you to train low-resource embedding models."
      ],
      "metadata": {
        "id": "fru9rqopIvc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.1 Load the amazon dataset in a variable called split and print the first 5 lines of the train set\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "from typing import List\n",
        "\n",
        "path_data_amazon = \"/home/ed/Dev/CODE_PERSO/data_tp2/amazon_reviews/\" # To replace with your local path or GoogleColab path\n",
        "\n",
        "paths_amazon_splits = {\n",
        "    key : os.path.join(path_data_amazon, f'{key}.jsonl.gz') for key in [\"train\", \"val\", \"test\"]\n",
        "}\n",
        "\n",
        "splits = {\n",
        "\n",
        "# `splits` should be of the form splits[\"train\"] = [\n",
        "#     {\n",
        "#         \"review\": 'Works great',\n",
        "#         \"rating\": 4.0\n",
        "#      ...\n",
        "#      }\n",
        "# ]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Your code here\n",
        "\n",
        "for i in range(5):\n",
        "    print(splits[\"train\"][i])\n"
      ],
      "metadata": {
        "id": "yYhFQsYAI80a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Plot the label distribution of the classes in the training set\n",
        "# You can copy paste and modify the function you made during the first practical session\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from typing import Any\n",
        "\n",
        "labels = [elem[\"category\"] for elem in splits[\"train\"]]\n",
        "\n",
        "\n",
        "def plot_distribution_histogram(list_labels: List[Any]):\n",
        "  # Your code here\n",
        "  pass\n",
        "\n",
        "plot_distribution_histogram(labels)"
      ],
      "metadata": {
        "id": "93Ffbm3eJfXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should obtain something like this:\n",
        "\n",
        "\n",
        "<a href=\"https://ibb.co/NTp03yN\"><img src=\"https://i.ibb.co/g4w07RW/labels-distribution.png\" alt=\"labels-distribution\" border=\"0\"></a>"
      ],
      "metadata": {
        "id": "o7EUS1xXKQLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Bag-of-Words Classification Methods\n",
        "\n",
        "- **BoW** methods are a simple family of methods to represent text data, treating it as a collection of words without considering grammar or word order.\n",
        "- Each word is mapped to a vector representing word frequencies or occurrences in a document.\n",
        "\n",
        "In this part we'll study two of those approaches: Naive Bayes classification and TF-IDF classification.\n",
        "\n",
        "### Advantages\n",
        "- **Simplicity**: Easy to implement.\n",
        "- **Efficiency**: Low resources approaches that scale well.\n",
        "- **Interpretability**: Easy to understand how classification works with word counts.\n",
        "- **Universal**: Language agnostic and domain agnostic\n",
        "\n",
        "\n",
        "### Lemmatization and Stop Words Removal in BoW\n",
        "\n",
        "In BoW, the final feature space is in the size of our number of unique words. To reduce\n",
        "the size of the feature space by removing the less informative words we usually peform to pre-processing steps: Lemmatization and Stop-words removel\n",
        "\n",
        "#### 1. Lemmatization or Stemming\n",
        "- **Definition**: Reducing words to their base or root form (e.g., 'running' to 'run').\n",
        "- **Why Use It?**: Minimizes redundancy by treating different forms of a word as the same feature, improving model performance.\n",
        "- **If no ressource are available**: In this context a simple `Stemmer` could be built that would remove common suffixes or prefixes of words such as marks of plurals, conjugations, gender, case endings...\n",
        "\n",
        "\n",
        "#### 2. Stop Words Removal\n",
        "- **Definition**: Removing common words (e.g., 'the', 'is') that carry little semantic value.\n",
        "- **Why Use It?**: Reduces noise, improves computational efficiency, and prevents irrelevant words from influencing the model.\n",
        "- **If no ressource are available**: A simple stop word list can be created by calculating word frequencies across a corpus, selecting the most frequent and semantically insignificant words, and optionally refining the list manually."
      ],
      "metadata": {
        "id": "kntuyRfqKw_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the lemmatization and the stop word removal we'll use a known library called Spacy. It is available for many languages (See https://spacy.io/usage/models).\n",
        "\n",
        "We first need to download the english models"
      ],
      "metadata": {
        "id": "XwzjtTSMLUKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "7OS4k934Lnfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are two code snippets that show you how to use the lemmatizer and the stopword removal functions of spacy"
      ],
      "metadata": {
        "id": "aBz33c0GLr4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a code snippet that shows how to use the spaCy lemmatizer\n",
        "\n",
        "import spacy\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"The cats are running faster than the dogs.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the lemmas\n",
        "lemmatized = [token.lemma_ for token in doc]\n",
        "print(lemmatized)"
      ],
      "metadata": {
        "id": "OUlR8luRL0z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a code snipppet that shows how to use the spaCy stopwords filter\n",
        "import spacy\n",
        "\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"The cats are running faster than the dogs.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Filter out stop words\n",
        "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "id": "RVcXMpcpL4u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 Process the three splits by creating a lemmatized and without stop words version\n",
        "# Only keep words that are composed of letters, lowercase all the words, and remove accents\n",
        "# Create entries named lemmatized_no_stopwords in the splits dictionary (see below for the expected output)\n",
        "#\n",
        "# splits[\"train\"][0] = {'review': 'Works great / packaged in box was great too.',\n",
        "#  'rating': 4.0,\n",
        "#  'category': 'Appliances',\n",
        "#  'lemmatized_no_stopwords': ['work', 'great', 'package', 'box', 'great']}\n",
        "\n",
        "# The function to remove accents is supplied below\n",
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nkfd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
        "\n",
        "def lemmatize_and_remove_stopwords(splits: dict):\n",
        "\n",
        "    # Your code here\n",
        "    return splits\n",
        "\n",
        "splits = lemmatize_and_remove_stopwords(splits)\n"
      ],
      "metadata": {
        "id": "b3bMkPlZL78u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Model: Naive Bayes Classification\n",
        "\n",
        "## Overview\n",
        "Naive Bayes is a probabilistic classifier based on Bayes' theorem, assuming independence between features. It is particularly effective for text classification tasks.\n",
        "\n",
        "## Bag of Words Model\n",
        "The Bag of Words (BoW) model represents text data by converting it into a matrix of token counts. Each document is transformed into a vector where each element corresponds to the frequency of a word in the document.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. **Text Preprocessing**:\n",
        "   - Tokenization: Split text into words.\n",
        "   - Lowercasing: Convert all words to lowercase.\n",
        "   - Stop-word removal: Eliminate common words (e.g., \"and\", \"the\").\n",
        "   - Stemming/Lemmatization: Reduce words to their root forms.\n",
        "\n",
        "2. **Vocabulary Creation**:\n",
        "   - Build a vocabulary of unique words from the training dataset.\n",
        "\n",
        "3. **Feature Extraction**:\n",
        "   - Convert documents into vectors based on the vocabulary using count or TF-IDF.\n",
        "\n",
        "4. **Training the Model**:\n",
        "   - Calculate prior probabilities for each class:\n",
        "   \n",
        "    \\begin{align}\n",
        "     P(Class) = \\frac{Count(Class)}{Total\\ Count}\n",
        "    \\end{align}\n",
        "   - Calculate likelihood probabilities:\n",
        "   \n",
        "     $$\n",
        "     P(Word|Class) = \\frac{Count(Word \\cap Class) + 1}{Count(Class) + V}\n",
        "     $$\n",
        "     where $ V $ is the size of the vocabulary (Laplace smoothing).\n",
        "\n",
        "5. **Classification**:\n",
        "   - For a new document, compute the posterior probability for each class:\n",
        "     $$\n",
        "     P(Class|Document) \\propto P(Class) \\prod_{i} P(Word_i|Class)\n",
        "     $$\n",
        "   - Choose the class with the highest posterior probability.\n",
        "\n",
        "## Advantages\n",
        "- Simple and fast.\n",
        "- Works well with large datasets.\n",
        "- Handles high dimensionality effectively.\n",
        "\n",
        "## Disadvantages\n",
        "- Assumes independence of features.\n",
        "- May perform poorly with highly correlated features.\n",
        "\n",
        "## Use Cases\n",
        "- Spam detection.\n",
        "- Sentiment analysis.\n",
        "- Document categorization."
      ],
      "metadata": {
        "id": "v6SecdECMUKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a code snippet that shows how to use the spaCy lemmatizer\n",
        "\n",
        "import spacy\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"The cats are running faster than the dogs.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the lemmas\n",
        "lemmatized = [token.lemma_ for token in doc]\n",
        "print(lemmatized)"
      ],
      "metadata": {
        "id": "YvFK7fKF0fiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a code snipppet that shows how to use the spaCy stopwords filter\n",
        "import spacy\n",
        "\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"The cats are running faster than the dogs.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Filter out stop words\n",
        "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "id": "Vk2SrXSM0gPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.1 Process the three splits by creating a lemmatized and without stop words version\n",
        "# Only keep words that are composed of letters, lowercase all the words, and remove accents\n",
        "# Create entries named lemmatized_no_stopwords in the splits dictionary (see below for the expected output)\n",
        "#\n",
        "# splits[\"train\"][0] = {'review': 'Works great / packaged in box was great too.',\n",
        "#  'rating': 4.0,\n",
        "#  'category': 'Appliances',\n",
        "#  'lemmatized_no_stopwords': ['work', 'great', 'package', 'box', 'great']}\n",
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nkfd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
        "\n",
        "def lemmatize_and_remove_stopwords(splits: dict):\n",
        "    pass\n",
        "    return splits\n",
        "\n",
        "# --- Solution\n",
        "\n",
        "def lemmatize_and_remove_stopwords(splits: dict):\n",
        "    for split in splits:\n",
        "        for elem in splits[split]:\n",
        "            doc = nlp(elem[\"review\"])\n",
        "            elem[\"lemmatized_no_stopwords\"] = [remove_accents(token.lemma_.lower()) for token in doc if not token.is_stop and token.text.isalpha()]\n",
        "    return splits\n",
        "\n",
        "splits = lemmatize_and_remove_stopwords(splits)"
      ],
      "metadata": {
        "id": "orNrzhKrMCuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Model: Naive Bayes Classification"
      ],
      "metadata": {
        "id": "UeJaVHmH0lsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Using CountVectorizer and BernoulliNB from scikit-learn, train a Naive Bayes classifier on the training set\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "category2id = {category: i for i, category in enumerate(np.unique([elem[\"category\"] for elem in splits[\"train\"]]))} # Can be useful to transform categories' labels to integer and vice-versea\n",
        "id2category = {i: category for category, i in category2id.items()}\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "X_train, y_train = None, None\n",
        "# Your code here\n",
        "\n",
        "\n",
        "clf_nb = BernoulliNB()\n",
        "clf_nb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "uvhxttjT0l_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Evaluate the peformance of your Naive Bayes classifier on the test set\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_test, y_test = None, None\n",
        "\n",
        "# Your code here\n",
        "\n",
        "\n",
        "print(classification_report(y_test, clf_nb.predict(X_test), target_names=category2id.keys()))"
      ],
      "metadata": {
        "id": "DqRdq_o50qbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO\n",
        "\n",
        "Independently of the energy measurement, how would you quantify the computational and memory complexity of Naive Bayes approach ?\n",
        "- Express the computation complexity of training as a function of the number of words in the training set\n",
        "- Express the memory complexity as function of variables of your choice"
      ],
      "metadata": {
        "id": "C0imTtK30s_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 Log probabilities of each word for each class can be found in the feature_log_prob_ array\n",
        "# Extract top-10 words per class and print them\n",
        "\n",
        "log_probabilities = clf_nb.feature_log_prob_\n",
        "\n",
        "# You will need the inverse_transform function from count_vectorizer\n",
        "\n",
        "\n",
        "top_words = {}\n",
        "for k in range(6):\n",
        "    # Your code here\n",
        "    pass"
      ],
      "metadata": {
        "id": "T471g_L_0q7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Model: TF-IDF Classification\n",
        "TF-IDF, or \"Term-frequency - inverse document frequency,\" is a method used to determine which words are the most discriminative in a text corpus.\n",
        "\n",
        "It's an approach that can model documents as such.\n",
        "\n",
        "TF-IDF is a score assigned to a word relative to a document. This score is calculated using two terms:\n",
        "\n",
        "## TF \"term-frequency\":\n",
        "\n",
        "The number of occurrences of the word \"cat\" in document *i*:\n",
        "\n",
        "$TF_i(w_{cat}) = count(w_{cat},document_i)$\n",
        "\n",
        "## IDF \"inverse document frequency\":\n",
        "\n",
        "$IDF(w_{cat}) = \\frac{\\text{Total number of documents in the corpus}}{\\text{Number of documents in which cat appears}}$\n",
        "\n",
        "## Therefore, the TF-IDF of the word \"cat\" for document *i* is:\n",
        "\n",
        "$TFIDF_i(w_{cat}) = TF_i(w_{cat}) \\cdot IDF(w_{cat})$\n",
        "\n",
        "We note that the more frequent the word \"cat\" is in the corpus, the lower its IDF.\n",
        "\n",
        "Conversely, the more frequent the word \"cat\" is in document *i*, the higher its TF.\n",
        "\n",
        "Words with the highest scores for document *i* will be frequent in this document and rare in the corpus, making them adequate to discriminate this type of document!\n",
        "\n",
        "## Remarks:\n",
        "\n",
        "Variants exist to limit the size of TF and IDF terms by applying the logarithmic function. We activate one of those variants with the option `sublinear_tf=True`"
      ],
      "metadata": {
        "id": "6TE4djdV0xSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 Fit the below TFidfVectorizer to your preprocessed BoW representation of your training set\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(min_df=3, max_df=0.8, sublinear_tf=True, norm='l2')\n",
        "\n",
        "# Your code here\n"
      ],
      "metadata": {
        "id": "COlaAn5x0wei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5 Fit a logistic regression classifier to predict category from the tf-idf representations\n",
        "# print the classification report on the test set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf_logistic = LogisticRegression(random_state=0, max_iter=3000)\n",
        "\n",
        "X_test, y_test = None, None\n",
        "\n",
        "# Your code here\n",
        "\n",
        "\n",
        "print(classification_report(y_test, clf_logistic.predict(X_test), target_names=category2id.keys()))\n"
      ],
      "metadata": {
        "id": "Oyqnxf1X00OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.6 count the number of zero-entries in X_train\n"
      ],
      "metadata": {
        "id": "NFkrt_m001un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "\n",
        "What can you say about the sparsity of X_train? (2-3 sentences)\n"
      ],
      "metadata": {
        "id": "SqZinjQH03X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Semantic Indexing (LSI): An extension of TF-IDF\n",
        "\n",
        "If you know PCA (Principal Component Analysis), or its equivalent SVD (Singular Value Decomposition), we can extract axes that explain the most the variability of our data. We can thus truncate and densify the representation by only keeping the k axes that explain the most the data variability.\n",
        "\n",
        "This approach of dimensionality reduction is called Truncated Singular Value Decomposition.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Jila-Ayubi/publication/271076899/figure/fig1/AS:614261244051470@1523462701842/Singular-value-decomposition-of-A-a-full-rank-r-b-rank-k-approximation.png\">"
      ],
      "metadata": {
        "id": "vut5Blm404-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.7 Truncate the svd for different number of components and fit a logistic regression model\n",
        "# Plot the evolution of f1_macro function of the number of components\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "for n in [8,16,32,128,256]:\n",
        "    svd = TruncatedSVD(n_components=n, n_iter=50, random_state=42)\n",
        "\n",
        "    X_train = None # TODO: modify\n",
        "\n",
        "    svd.fit(X_train)\n",
        "\n",
        "    # Your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "uIkyeyyA03kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.8 Plot the confusion matrix for the smallest and highest number of component\n",
        "# Below a code to plot the confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = [id2category[i] for i in range(6)]\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xticks(ticks=np.arange(len(labels))+0.5, labels=labels)\n",
        "plt.yticks(ticks=np.arange(len(labels))+0.5, labels=labels, rotation=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RjGk6IGK09Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO\n",
        "\n",
        "Do you note anything between the two confusion matrices? (1-2 sentences)"
      ],
      "metadata": {
        "id": "_I40MHLL0_-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train your TF-IDF on wikipedia\n",
        "\n",
        "Sometimes the quantity of data available isn't sufficient to actually build interesting tf-idf representations.\n",
        "\n",
        "In those case one can try to learn the idf coefficients through the use of another big corpus.\n",
        "\n",
        "Here we're going to do it through the use of a corpus of 100k paragraphs from 103 articles.\n"
      ],
      "metadata": {
        "id": "JiDohIWJ1BRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "\n",
        "Explain why the dataset is not ideal? (2-3 sentences)"
      ],
      "metadata": {
        "id": "ZjS2I1Zd1Czg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.9 learn a tf-idf on wiki-103\n",
        "\n",
        "#TODO: Modify with your path\n",
        "path_wikipedia = \".../wikitext-103/wiki-103-extract-100k.jsonl.gz\"\n",
        "\n",
        "# You can pass a generator to the fit() method to not overload your ram memory\n",
        "text_generator = (json.loads(line)[\"text\"] for line in gzip.open(path_wikipedia, \"rt\"))\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, max_df = 0.8, min_df=10, norm='l2')\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "8rigct7J0_Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.10 transform your training set, learn a logistic regression classifier and plot the classification_report"
      ],
      "metadata": {
        "id": "jqr3XdMI1NJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Word Embeddings: Fasttext and Word2Vec\n",
        "\n",
        "FastText and Word2Vec are two popular algorithms for generating word embeddings, which are dense vector representations of words in a continuous vector space. There's also a third popular algorithm called GloVe, which we'll not cover in this session, as is very different from the two others.\n",
        "\n",
        "Those two models exist in two flavors: Skip-gram and Continuous Bag of Words (CBOW). The main difference between the two is the way they are trained. Skip-gram predicts context words from a target word, while CBOW predicts the target word based on its context.\n",
        "\n",
        "![word2vec](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*cuOmGT7NevP9oJFJfVpRKA.png)\n",
        "\n",
        "## Word2Vec\n",
        "- **Training**: Trains using Skip-gram or Continuous Bag of Words (CBOW) models. It converts words into dense vectors based on their context within a window.\n",
        "  - **Skip-gram**: Predicts context words from a target word.\n",
        "  - **CBOW**: Predicts the target word based on its context.\n",
        "\n",
        "## FastText\n",
        "- **Training**: Also supports Skip-gram and CBOW. Key difference: it represents words as a bag of character **n-grams**.\n",
        "  - Instead of mapping each word directly, it breaks words into subword units, helping with rare words and morphology.\n",
        "\n",
        "## Similarities\n",
        "- Both use Skip-gram and CBOW.\n",
        "- Both output dense word vectors.\n",
        "- Both leverage surrounding context in training.\n",
        "\n",
        "## Differences\n",
        "- **FastText**: Uses subword information (character n-grams), improving performance with rare/unknown words.\n",
        "- **Word2Vec**: Treats each word as a single entity, making it less effective for rare words or inflectional languages.\n",
        "\n",
        "In FastText word representations are thus computed as the average of the representations of its character n-grams.\n",
        "Example: The word `elephant` can be represented as the sum of its character n-grams `'<elep', 'eleph', 'lepha', 'ephan', 'phant', 'hant>'`.\n",
        "\n",
        "\n",
        "## FastText in Supervised Setting\n",
        "\n",
        "FastText can be also be trained in supervised settings such as text classification. In a supervised setting, it learns word and sentence representations while simultaneously training a classifie\n",
        "\n",
        "In this part we'll only use fasttext in unsupervised setting by using the model pretrained on wikipedia"
      ],
      "metadata": {
        "id": "wJEYIdsw1OXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Load the fasttext model cc.en.300.bin\n",
        "import fasttext\n",
        "\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "xS_lnSNE1Pb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 Using the get_sentence_vector() method add for each entry of split its sentence vector representation from a lemmatized without stopwords version of the review. Add the representation in a field \"fasttext_wiki\" for each entry\n",
        "\n",
        "for split in splits.keys():\n",
        "    for elem in splits[split]:\n",
        "        # Your code here\n",
        "        pass"
      ],
      "metadata": {
        "id": "qvFq9b211VRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3 Train a logistic regression model and print its classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test, y_pred = None\n",
        "clf_logistic = LogisticRegression(random_state=0, max_iter=3000)\n",
        "\n",
        "# Your code here\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "S5fnYvzU1V4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "Explain to what extent fasttext representations are expected to be better than tf-idf ones on wikipedia?\n",
        "\n",
        "Explain to what extent they're expected to be less relevant too?\n",
        "\n",
        "(2-3 sentences)"
      ],
      "metadata": {
        "id": "cU_GEjYs1Yo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weighted Fasttext:\n",
        "\n",
        "We can try to make use of the best of both worlds by using the idf coefficient to weight the sum of our fasttext features."
      ],
      "metadata": {
        "id": "-X3JwVqH1aq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we supply some functions to compute average representations using Fasttext and IDF coefficients\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_idf_coefs(words, tfidf):\n",
        "    \"\"\"\n",
        "    Given a tf-idf model, this functions only return the words that have an entry in the tf-idf matrix\n",
        "    It also return their associated idf coefficients\n",
        "    \"\"\"\n",
        "    indices = [tfidf.vocabulary_.get(word) for word in words]\n",
        "    filtered_words = [words[i] for i in range(len(words)) if indices[i] is not None]\n",
        "    idf_coefs = [tfidf.idf_[i] for i in indices if not(i is None)]\n",
        "    return filtered_words, idf_coefs\n",
        "\n",
        "def average_word_vectors(model, words, idf_coefs = None):\n",
        "    \"\"\"\n",
        "    This function computes the average word vector of a list of words.\n",
        "    If no idf_coefs are provided, it computes the simple average.\n",
        "    If idf_coefs are provided, it computes the weighted average.\n",
        "    \"\"\"\n",
        "    word_vectors = [model.get_word_vector(word) for word in words]\n",
        "    if not(idf_coefs is None):\n",
        "        # Your code here\n",
        "        # The list of coefs should be normalized to sum to 1 using the method of your choice\n",
        "        return None\n",
        "    else:\n",
        "        return np.average(word_vectors, axis=0)\n"
      ],
      "metadata": {
        "id": "GOEX-DsU1Y-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4 Make idf weighted average representation in splits called `weighted_fasttext`\n",
        "# For reviews that don't have any words in the tf-idf model, use the simple average representation"
      ],
      "metadata": {
        "id": "Bzzbla411f8I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5 Train a logistic regression model and print its classification_report"
      ],
      "metadata": {
        "id": "GjAswNgn1gca"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "\n",
        "Are the results as expected? (1-2 sentences)"
      ],
      "metadata": {
        "id": "rijIqMRk1llF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Tiny Bert (Bonus part)\n",
        "\n",
        "In this part we concentrate on the use of a pretrained encoder-model composed of two BertEncoder layers.\n",
        "\n",
        "We're going to perform finetuning of this model in two settings (full-finetuning and Lora finetuning (which is related to dimensionality reduction))"
      ],
      "metadata": {
        "id": "-QtYD-oG1nBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model of interest\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "bert_model = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "1a0d3a2717bb48248e79839d929ea675",
            "c56da4714e94476180d13f24058936fc",
            "bad7121b7bd04acd8ae61fc49f4cbd3a",
            "89f07412b4d64d4bb645cbbd997daea9",
            "553ce819bc7a40469186f008adeefec6",
            "5131e5a62c4d4e7fa3d3cd19068aae6b",
            "200e6c2b01864797abedc2d7f635aaed",
            "9b7676d043b7427c936929a3162db0a9",
            "38a64b3a93d444dbae6736a0a282828e",
            "51752f856fc2404287d5007badad3f7d",
            "f3861f247b334c2f81769c20e8aad40f",
            "5120f8e4349943208f54df6a63f35f95",
            "e5e5916d1e7644e7a3a71132a2beb56b",
            "aeeb8971d539407ea40dcbe9f41e3311",
            "535904ba4d284bc380afd12a8f13f45c",
            "c6efa6218d7444b68ed20c13fdccf5b1",
            "add67ccc0e304393b06efa036722e4a3",
            "b735d0c26d4841b9966d54b6f95bc85e",
            "ee51cb8dfc554c6883a2fc7a27d71923",
            "b46afa62731648e0a33cc0c3df399dae",
            "d1f0f81596f04ccaac13f80ca37a37f3",
            "e575129332614dd5abe65fb124d357dd",
            "eb5a85460dac4b76a8643b8ce4b3d55b",
            "97eee5a112be4cb4ae1b0464da5da1d6",
            "473a4874c9204919889df7830439f270",
            "a20a85b8f5104512a0b9c77f8f93f04b",
            "943f8fa6fa4842e98b2ac8473d718f69",
            "8219c7841d81478fbb3f0590c68f8db5",
            "73debcbd38d946a98a7c066ccb6c8d84",
            "1e6a76c7958f4b139154e043eaac1907",
            "61ad78ec17114502a1299ca7cf63883a",
            "b1bd4b5a6d684fa69b5b8f235420d8cb",
            "849d06633a8e43379e2d3db0ddcb454a"
          ]
        },
        "id": "99UMAv041j1O",
        "outputId": "a05ba682-4de2-4c6f-bf06-cc32e00a7792"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a0d3a2717bb48248e79839d929ea675"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5120f8e4349943208f54df6a63f35f95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb5a85460dac4b76a8643b8ce4b3d55b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we supply two classes, one for the head classification and one for the full model\n",
        "import torch\n",
        "\n",
        "class HeadClassification(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\"\n",
        "        input_dim: size of hidden layer (pooled_output)\n",
        "        output_dim: number of classes\n",
        "        \"\"\"\n",
        "        super(HeadClassification, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (batch_size, input_dim)\n",
        "        return unnormalized logits of shape (batch_size, output_dim)\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "class BertForClassification(torch.nn.Module):\n",
        "    def __init__(self, bert, input_dim, output_dim):\n",
        "        \"\"\"\n",
        "        bert: bert model\n",
        "        output_dim: number of classes\n",
        "        \"\"\"\n",
        "        super(BertForClassification, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.input_dim = input_dim\n",
        "        self.classifier = HeadClassification(self.input_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, **kwargs):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        ""
      ],
      "metadata": {
        "id": "40tUS7Jt1o93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we supply two classes, this time for the dataset and dataloader in pytorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X: List[np.array], y: List[int]):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class Datacollator:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        X = [elem[0] for elem in inputs]\n",
        "        y = [elem[1] for elem in inputs]\n",
        "        batch = tokenizer.batch_encode_plus(X, return_tensors=\"pt\", padding=\"longest\")\n",
        "        labels = torch.tensor(y)\n",
        "        return batch, labels\n",
        "\n",
        "\n",
        "# Create the dataset\n",
        "dataset = MyDataset(X_train, y_train)\n",
        "\n",
        "data_collator = Datacollator(tokenizer)\n",
        "\n",
        "# Create the dataloader\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)``\n",
        "f"
      ],
      "metadata": {
        "id": "xo4xCPCb1rsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearWarmupScheduler:\n",
        "    \"\"\"\n",
        "    This class implements a usual learning rate scheduling with warmups steps followed by linear decay of the learning rate after each `scheduler.step()` calls\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, training_steps):\n",
        "        self.optimizer = optimizer\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.training_steps = training_steps\n",
        "\n",
        "    def __call__(self, current_step: int):\n",
        "        return self.warmup(current_step)\n",
        "\n",
        "    def warmup(self, current_step: int):\n",
        "        if current_step < self.warmup_steps:  # current_step / warmup_steps * base_lr\n",
        "            return float(current_step / self.warmup_steps)\n",
        "        else:                                 # (num_training_steps - current_step) / (num_training_steps - warmup_steps) * base_lr\n",
        "            return max(0.0, float(self.training_steps - current_step) / float(max(1, self.training_steps - self.warmup_steps)))\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1Uix6p31tnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 Load the validation dataloader"
      ],
      "metadata": {
        "id": "P5UuajbY1vDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Complete the training loop\n",
        "# Save the model that has the best validation loss after an epoch\n",
        "# You can use `best_model` = copy.deepcopy(model)\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "best_val_loss = float('inf')\n",
        "epochs_without_improvement = 0\n",
        "patience = 8  # Number of epochs with no improvement after which training will be stopped\n",
        "num_epochs = 40\n",
        "learning_rate = 1e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "best_model = None\n",
        "\n",
        "### TODO: Modify\n",
        "\n",
        "classification_model = None\n",
        "train_loader = None\n",
        "val_loader= None\n",
        "\n",
        "###\n",
        "\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(classification_model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "training_steps = len(train_loader) * num_epochs\n",
        "linearwarmup_func =  LinearWarmupScheduler(optimizer, warmup_steps=int(0.1*training_steps), training_steps=int(training_steps))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=linearwarmup_func)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    classification_model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classification_model.forward(**inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Epoch {epoch}, Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    validation_loss = 0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        classification_model.eval()\n",
        "        for inputs, labels in val_loader:\n",
        "            y_true += labels.squeeze().tolist()\n",
        "            outputs =  classification_model.forward(**inputs)\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "            y_pred += predictions.squeeze().tolist()\n",
        "            validation_loss += criterion(outputs, labels).item()\n",
        "        f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
        "        print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
        "    validation_loss /= len(val_loader)\n",
        "\n",
        "    # Early stopping check\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {validation_loss:.4f}\")\n",
        "    if validation_loss < best_val_loss:\n",
        "        best_val_loss = validation_loss\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
        "        break"
      ],
      "metadata": {
        "id": "psKhQmtv1wFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 Measure the model performance using the classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "njGS7AEo1xi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reducing the computational and memory complexity of transformer finetuning\n",
        "### LoRA (Low-Rank Adaptation) for Transformer Fine-tuning\n",
        "\n",
        "LoRA is a technique to reduce the number of trainable parameters during fine-tuning by injecting trainable low-rank matrices into the pre-trained model's weight matrices. Instead of updating the entire weight matrix, LoRA introduces low-rank factorization.\n",
        "\n",
        "\n",
        "![lora](https://www.researchgate.net/profile/Ruibo-Fu/publication/371490294/figure/fig1/AS:11431281167009019@1686539371648/Transformer-architecture-in-wav2vec2-along-with-LoRA.png)\n",
        "\n",
        "\n",
        "#### Key Concepts:\n",
        "\n",
        "- **Rank (r):** The rank of the factorized matrices. It controls the dimensionality of the introduced low-rank matrices. A lower rank reduces the trainable parameters but may limit the model's capacity.\n",
        "  \n",
        "- **Alpha (α):** A scaling factor applied to the learned low-rank matrices before they are added to the original weight matrix. It controls how much influence the low-rank matrices have.\n",
        "\n",
        "LoRA fine-tunes transformers efficiently with fewer trainable parameters by modifying only the low-rank matrices.\n"
      ],
      "metadata": {
        "id": "LgYuQPZx1y4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is a manual implementation of LoRa where each BerEncoder layer is changed into its LoRa version\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, original_layer, r=4, alpha=16):\n",
        "        super().__init__()\n",
        "        self.original_layer = original_layer\n",
        "        self.r = r\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Set requires_grad to False for the original layer\n",
        "        for param in self.original_layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Initialize LoRA components\n",
        "        self.lora_A = nn.Parameter(torch.randn(original_layer.weight.size(0), r))\n",
        "        self.lora_B = nn.Parameter(torch.randn(r, original_layer.weight.size(1)))\n",
        "        self.scaling = alpha / r\n",
        "\n",
        "        # Optional: Initialize LoRA matrices to zero to not affect the original layer at the start\n",
        "        nn.init.zeros_(self.lora_A)\n",
        "        nn.init.zeros_(self.lora_B)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Original layer output\n",
        "        original_output = self.original_layer(x)\n",
        "\n",
        "        # LoRA output: Adding scaled low-rank matrices' contribution\n",
        "        lora_output = (x @ self.lora_B.T) @ self.lora_A.T\n",
        "        lora_output *= self.scaling\n",
        "\n",
        "        return original_output + lora_output\n",
        "\n",
        "class BertWithLoRA(nn.Module):\n",
        "    def __init__(self, model_name='prajjwal1/bert-tiny', r=8, alpha=16):\n",
        "        super().__init__()\n",
        "        # Load the pre-trained BERT model\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze all parameters in the model\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Apply LoRA to the last encoder layer's attention projection (e.g., output layer of the last attention head)\n",
        "        for layer in self.bert.encoder.layer:\n",
        "            attention_head = layer.attention.self\n",
        "            layer.attention.self.query = LoRALayer(attention_head.query, r, alpha)\n",
        "            layer.attention.self.key = LoRALayer(attention_head.key, r, alpha)\n",
        "            layer.attention.self.value = LoRALayer(attention_head.value, r, alpha)\n",
        "            layer.attention.output.dense = LoRALayer(layer.attention.output.dense, r, alpha)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        return self.bert(input_ids=input_ids, attention_mask=attention_mask)\n"
      ],
      "metadata": {
        "id": "XcYDzUUo1zKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.4 Re-implement the training loop but using the Lora augmented model"
      ],
      "metadata": {
        "id": "Ja5pHJiU12Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.5 Using the classification_report function compare the performances of the two models"
      ],
      "metadata": {
        "id": "qJBcfM3u13rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Todo\n",
        "\n",
        "What are your explanations for this underperforming of transformer models compared to much lighter approaches in this practical session?"
      ],
      "metadata": {
        "id": "MW8B4SW716nb"
      }
    }
  ]
}